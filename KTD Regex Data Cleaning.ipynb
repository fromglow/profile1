{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional notes for github\n",
    "## Using regex \n",
    "Complex regex techniques have been used to clean up text files to extract dialogues from individual characters. This was an earlier project (Oct-Dec 2021). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regex to clean up data from online txt files of Oscar Wilde plays\n",
    "\n",
    "The corpora for this NLP project consisted of looking at specifically Oscar Wilde plays. The need was to create individual files containing the lines of each character in each play. Eventually, this would be fed into a fine-tuned LSTM to generate outputs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all necessary packages\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLPMP1\n",
    "#At the beginning, the file is manually cleaned of any introductory or concluding text, \n",
    "#or any general text associated with online ebooks that is not a part of the play. \n",
    "#Additionally, scene beginnings and set designs are also deleted manually. \n",
    "\n",
    "lwfo = open(r'C:\\Users\\____\\Documents\\GitHub\\nlp-21-22\\data\\lwfan1.txt', 'r') \n",
    "# opens the original file with, with the text set to be read (not edited or changed)\n",
    "pfr = lwfo.read() \n",
    "#pfr - play first read, pfr is a variable that stores the individual lines of the play being read\n",
    "\n",
    "reg1 = r\"\\[.+?\\n?.+?\\]\" # regex to remove anything in square brackets \n",
    "#This works for square brackets that are separated by a newline\n",
    "#I tried using other regex expressions such as \"+\", \"*\", or \"{}\"\n",
    "#to accommodate for square brackets longer than two lines, \n",
    "#however this was met with limited success and I clean up the rest of the square bracket manually\n",
    "\n",
    "pfr = re.sub(reg1, \"\", str(pfr), flags=re.M) \n",
    "#substitutes in the square brackets and contents with nothing, thereby removing it\n",
    "\n",
    "reg2 = r'(?<=[A-Z]{5})(?:\\.\\s\\s){1}' #regex to precede the characters spoken lines with an equals sign\n",
    "#in Lady Windermere's Fan, characters lines have the characters names, \n",
    "#all of which have at least 5 capital letters, before a fullstop and two empty spaces \".  \"\n",
    "#after which a character's lines begins.\n",
    "#Thus, the regex changes the \".  \" to an equals sign.\n",
    "#An equals sign was used as after manual inspection of the text, equals signs were not found in the text\n",
    "#or were generally rare.\n",
    "#Due to this, an equals sign makes for a useful delineater through which to separate character lines\n",
    "#for future purposes of using regex to create txt files for individual character's lines. \n",
    "\n",
    "pfr = re.sub(reg2, '=', pfr, flags=re.M) #substitues in \".  \" with an equals sign\n",
    "\n",
    "lwfe = open(r'C:\\Users\\____\\Documents\\GitHub\\nlp-21-22\\data\\lwfan2.txt', 'w') \n",
    "#creates a new file to write things into\n",
    "per = lwfe.write(str(pfr)) \n",
    "#writes into new file the cleaned up string from the original txt file\n",
    "\n",
    "lwfe.close() \n",
    "lwfo.close()\n",
    "#closes both txt files, which means manual editing can take place if necessary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLPMP2\n",
    "#The following code was used to remove newlines\n",
    "\n",
    "lwfo = open(r'C:\\Users\\____\\Documents\\GitHub\\nlp-21-22\\data\\lwfan_n9.txt', 'r') \n",
    "pfr = lwfo.read() \n",
    "#as earlier, the text is opened in read mode, and the lines are individually read and recorded\n",
    "\n",
    "#reg2 = r'\\n(?=[a-z]{3})' # used to remove any new lines preceding any three alphabet characters\n",
    "#reg2 = r'\\n(?=\\n{1})' # used to remove any newlines preceding a newline\n",
    "#reg2 = r'\\n(?=[^A-Z]{3})' #used to remove any newlines not preceding any three capital letters\n",
    "reg2 = r'\\n(?![A-Z]{3})' #used to remove any newlines not preceding any three capital letters\n",
    "#while the above two regex expressions are similar, the expression that is\n",
    "#'\\n(?![A-Z]{3})' can tend to include newlines while the above does not\n",
    "#these 4 expressions were used and while some share similarity,\n",
    "#it was to ensure the data cleaning was thorough\n",
    "#the 4 were used in succession and if any issues presented themselves after manual inspection\n",
    "#relevant regex expressions were re-applied\n",
    "pfr = re.sub(reg2, ' ', pfr, flags=re.M) \n",
    "#the above line removes the new line and replaces it with a whitespace. \n",
    "#A whitespace is relevant as without it, any characters separated solely by a new line\n",
    "#would then be combined. Therefore, a whitespace is used to replace a newline. \n",
    "\n",
    "lwfe = open(r'C:\\Users\\____\\Documents\\GitHub\\nlp-21-22\\data\\lwfan_n10.txt', 'w') \n",
    "per = lwfe.write(str(pfr)) \n",
    "lwfe.close()\n",
    "lwfo.close()\n",
    "#as earlier, a new file is used to write the cleaned txt file into and the files are then closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLPMP3\n",
    "\n",
    "lwfo = open(r'C:\\Users\\____\\Documents\\GitHub\\nlp-21-22\\data\\lwfan_n10.txt', 'r') \n",
    "pfr = lwfo.read() \n",
    "#As above, the file is opened and read\n",
    "\n",
    "reg2 = r'(?<=\\nMRS\\. ERLYNNE=).+(?=\\n)'\n",
    "#The above regex finds any line that is in between a character's name and the proceeding nextline. \n",
    "#As we cleaned for most newlines, we were left with a txt file where each character's line begins \n",
    "#with the character's name in capital letters, proceeded by an equal sign, and after their line, \n",
    "#A newline begins. \n",
    "\n",
    "#An alternate way of writing the above is below\n",
    "#name = 'CHARACTER NAME'\n",
    "#reg2 = r'(?<=\\n' + name + '=).+(?=\\n)'\n",
    "#the above means that the character's name can be placed inside a variable to ease \n",
    "#typing in the character's name in the regex expression\n",
    "pfr = re.findall(reg2, str(pfr)) \n",
    "\n",
    "lwfe = open(r'C:\\Users\\____\\Documents\\GitHub\\nlp-21-22\\data\\lwfan_Erlynne.txt', 'a') \n",
    "#the above opens a new document in append mode, where each string produced is added to the text file\n",
    "\n",
    "#a for loop that goes through all the matches with the regex expression\n",
    "#and appends them to the new text file \n",
    "#and separates each match with a newline\n",
    "for i in pfr:\n",
    "    lwfe.write(i+'\\n')\n",
    "    \n",
    "#closing the files at the end\n",
    "lwfe.close()\n",
    "lwfo.close()\n",
    "\n",
    "#attemps to automate this with a for loop were made\n",
    "#the idea was to list the character names and then go through a for loop for that list\n",
    "#however, when it came to creating an output file such as \"lwfe\"\n",
    "#there were issues with separating the filepath into manageable variable sections\n",
    "#and parts were getting considered as string while other parts as variable text \n",
    "#As a result, this separation of characters into a file each for their names was done indivdually\n",
    "#combining text files to make arachetypes or to combine it based on age, gender, \n",
    "#or considered social status was also combined manually "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and citations\n",
    "\n",
    "Much of this work was possible due to the course materials provided in the Natural Language Processing module in my MSc course, the regex python documentation, and general sources such as stack overflow. They are cited below.  \n",
    "\n",
    "Citations:\n",
    "\n",
    "W3schools.com. 2021. Python For Loops. [online] Available at: <https://www.w3schools.com/python/python_for_loops.asp> [Accessed 1 December 2021].\n",
    "\n",
    "W3schools.com. 2021. Python File Open. [online] Available at: <https://www.w3schools.com/python/python_file_handling.asp> [Accessed 1 December 2021].\n",
    "\n",
    "Docs.python.org. 2021. re — Regular expression operations — Python 3.10.0 documentation. [online] Available at: <https://docs.python.org/3/library/re.html> [Accessed 1 December 2021].\n",
    "\n",
    "Stack Overflow. 2021. How to open a file using the open with statement. [online] Available at: <https://stackoverflow.com/questions/9282967/how-to-open-a-file-using-the-open-with-statement> [Accessed 1 December 2021].\n",
    "\n",
    "Texts accessed:\n",
    "\n",
    "Wilde, O., 2021. A Woman of No Importance. [online] Available at: <https://www.gutenberg.org/ebooks/854> [Accessed 1 December 2021].\n",
    "\n",
    "Wilde, O., 2021. An Ideal Husband : Wilde, Oscar, 1854-1900 : Free Download, Borrow, and Streaming : Internet Archive. [online] Internet Archive. Available at: <https://archive.org/details/anidealhusband00885gut> [Accessed 1 December 2021].\n",
    "\n",
    "Wilde, O., 2021. Lady Windermere's Fan : Wilde, Oscar, 1854-1900 : Free Download, Borrow, and Streaming : Internet Archive. [online] Internet Archive. Available at: <https://archive.org/details/ladywindermeresf00790gut> [Accessed 1 December 2021].\n",
    "\n",
    "Wilde, O., 2021. The Importance of Being Earnest. [online] https://www.gutenberg.org/ebooks/844. Available at: <https://www.gutenberg.org/ebooks/844> [Accessed 1 December 2021].\n",
    "\n",
    "Colab notebooks were used to generate text. Week 5 notebooks for fine-tuning a pre-trained LSTM were used which used the following cited github repositories:\n",
    "\n",
    "Woolf, M., 2021. GitHub - minimaxir/gpt-2-simple: Python package to easily retrain OpenAI's GPT-2 text-generating model on new texts. [online] GitHub. Available at: <https://github.com/minimaxir/gpt-2-simple> [Accessed 1 December 2021].\n",
    "\n",
    "Woolf, M., 2021. GitHub - minimaxir/textgenrnn: Easily train your own text-generating neural network of any size and complexity on any text dataset with a few lines of code.. [online] GitHub. Available at: <https://github.com/minimaxir/textgenrnn> [Accessed 1 December 2021].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
